{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fa5eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geos import lgeos\n",
    "from google.cloud import bigquery\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017aab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 77 rows to BigQuery table future-sonar-331521.cta_tracker.train_data\n",
      "Uploaded 78 rows to BigQuery table future-sonar-331521.cta_tracker.train_data\n",
      "Uploaded 76 rows to BigQuery table future-sonar-331521.cta_tracker.train_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up BigQuery client and credentials\n",
    "client = bigquery.Client.from_service_account_json('YOUR_BIGQUERY_CREDENTIALS')\n",
    "\n",
    "route_map = {'y': 'Yellow Line',\n",
    " 'org': 'Orange Line',\n",
    " 'pink': 'Pink Line',\n",
    " 'brn': 'Brown Line',\n",
    " 'g': 'Green Line',\n",
    " 'red': 'Red Line',\n",
    " 'blue': 'Blue Line',\n",
    " 'p': 'Purple Line'}\n",
    "\n",
    "\n",
    "# Define function to get data from CTA API and create dataframe\n",
    "def get_cta_data():\n",
    "    url = 'http://lapi.transitchicago.com/api/1.0/ttpositions.aspx'\n",
    "    params = {'key': 'YOUR_CTA_MAP_ID', 'rt': ['red,blue,brn,g,org,p,pink,y'], 'outputType': 'xml'}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.content, 'xml')\n",
    "    train_data = []\n",
    "    for route in soup.find_all('route'):\n",
    "        for train in route.find_all('train'):\n",
    "            train_dict = {'route': str(route_map[route['name']]),\n",
    "                          'run_number': int(train.rn.text),\n",
    "                          'destination_station_id': int(train.destSt.text),\n",
    "                          'destination_station_name': str(train.destNm.text),\n",
    "                          'train_direction': int(train.trDr.text),\n",
    "                          'next_station_id': int(train.nextStaId.text),\n",
    "                          'next_stop_id': int(train.nextStpId.text),\n",
    "                          'next_station_name': str(train.nextStaNm.text),\n",
    "                          'timestamp': dt.datetime.strptime(train.prdt.text, '%Y%m%d %H:%M:%S'),\n",
    "                          'arrival_time': dt.datetime.strptime(train.arrT.text, '%Y%m%d %H:%M:%S'),\n",
    "                          'is_approaching': int(train.isApp.text),\n",
    "                          'is_delayed': int(train.isDly.text),\n",
    "                          'latitude': float(train.lat.text),\n",
    "                          'longitude': float(train.lon.text),\n",
    "                          'heading': float(train.heading.text)}\n",
    "            train_data.append(train_dict)\n",
    "    df = pd.DataFrame(train_data)\n",
    "    return df\n",
    "\n",
    "# Define function to upload dataframe to BigQuery\n",
    "def upload_to_bigquery(df):\n",
    "    table_id = \"YOUR_BIGQUERY_PROJECT_ID\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=[\n",
    "            bigquery.SchemaField('route', 'STRING'),\n",
    "            bigquery.SchemaField('run_number', 'INTEGER'),\n",
    "            bigquery.SchemaField('destination_station_id', 'INTEGER'),\n",
    "            bigquery.SchemaField('destination_station_name', 'STRING'),\n",
    "            bigquery.SchemaField('train_direction', 'INTEGER'),\n",
    "            bigquery.SchemaField('next_station_id', 'INTEGER'),\n",
    "            bigquery.SchemaField('next_stop_id', 'INTEGER'),\n",
    "            bigquery.SchemaField('next_station_name', 'STRING'),\n",
    "            bigquery.SchemaField('timestamp', 'DATETIME'),\n",
    "            bigquery.SchemaField('arrival_time', 'DATETIME'),\n",
    "            bigquery.SchemaField('is_approaching', 'INTEGER'),\n",
    "            bigquery.SchemaField('is_delayed', 'INTEGER'),\n",
    "            bigquery.SchemaField('latitude', 'FLOAT'),\n",
    "            bigquery.SchemaField('longitude', 'FLOAT'),\n",
    "            bigquery.SchemaField('heading', 'FLOAT')\n",
    "        ],\n",
    "        write_disposition='WRITE_TRUNCATE'\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    job.result()  # Wait for job to complete\n",
    "    print('Uploaded {} rows to BigQuery table {}'.format(len(df), table_id))\n",
    "\n",
    "# Loop to get data and upload to BigQuery every 30 seconds\n",
    "while True:\n",
    "    df = get_cta_data()\n",
    "    upload_to_bigquery(df)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a06508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
